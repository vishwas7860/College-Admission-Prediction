{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WyRZkR2XjObi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"Admission_Predict.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "te6Vvcd8jg_k",
        "outputId": "a4f7ab93-2831-4487-92ff-35fdbe913e69"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
              "0           1        337          118                  4  4.5   4.5  9.65   \n",
              "1           2        324          107                  4  4.0   4.5  8.87   \n",
              "2           3        316          104                  3  3.0   3.5  8.00   \n",
              "3           4        322          110                  3  3.5   2.5  8.67   \n",
              "4           5        314          103                  2  2.0   3.0  8.21   \n",
              "\n",
              "   Research  Chance of Admit   \n",
              "0         1              0.92  \n",
              "1         1              0.76  \n",
              "2         1              0.72  \n",
              "3         1              0.80  \n",
              "4         0              0.65  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b1779c61-40dc-4e43-8176-51efdc750fd1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Serial No.</th>\n",
              "      <th>GRE Score</th>\n",
              "      <th>TOEFL Score</th>\n",
              "      <th>University Rating</th>\n",
              "      <th>SOP</th>\n",
              "      <th>LOR</th>\n",
              "      <th>CGPA</th>\n",
              "      <th>Research</th>\n",
              "      <th>Chance of Admit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>337</td>\n",
              "      <td>118</td>\n",
              "      <td>4</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>9.65</td>\n",
              "      <td>1</td>\n",
              "      <td>0.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>324</td>\n",
              "      <td>107</td>\n",
              "      <td>4</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>8.87</td>\n",
              "      <td>1</td>\n",
              "      <td>0.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>316</td>\n",
              "      <td>104</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>8.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>322</td>\n",
              "      <td>110</td>\n",
              "      <td>3</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>8.67</td>\n",
              "      <td>1</td>\n",
              "      <td>0.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>314</td>\n",
              "      <td>103</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.21</td>\n",
              "      <td>0</td>\n",
              "      <td>0.65</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b1779c61-40dc-4e43-8176-51efdc750fd1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b1779c61-40dc-4e43-8176-51efdc750fd1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b1779c61-40dc-4e43-8176-51efdc750fd1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.iloc[:,1:]\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4DitJ1Ucjouf",
        "outputId": "6818f1f3-916e-405c-d7cb-7b53075e1464"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
              "0        337          118                  4  4.5   4.5  9.65         1   \n",
              "1        324          107                  4  4.0   4.5  8.87         1   \n",
              "2        316          104                  3  3.0   3.5  8.00         1   \n",
              "3        322          110                  3  3.5   2.5  8.67         1   \n",
              "4        314          103                  2  2.0   3.0  8.21         0   \n",
              "\n",
              "   Chance of Admit   \n",
              "0              0.92  \n",
              "1              0.76  \n",
              "2              0.72  \n",
              "3              0.80  \n",
              "4              0.65  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7de4c4dd-907f-4446-80a8-8193dd2e2891\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GRE Score</th>\n",
              "      <th>TOEFL Score</th>\n",
              "      <th>University Rating</th>\n",
              "      <th>SOP</th>\n",
              "      <th>LOR</th>\n",
              "      <th>CGPA</th>\n",
              "      <th>Research</th>\n",
              "      <th>Chance of Admit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>337</td>\n",
              "      <td>118</td>\n",
              "      <td>4</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>9.65</td>\n",
              "      <td>1</td>\n",
              "      <td>0.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>324</td>\n",
              "      <td>107</td>\n",
              "      <td>4</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>8.87</td>\n",
              "      <td>1</td>\n",
              "      <td>0.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>316</td>\n",
              "      <td>104</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>8.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>322</td>\n",
              "      <td>110</td>\n",
              "      <td>3</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>8.67</td>\n",
              "      <td>1</td>\n",
              "      <td>0.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>314</td>\n",
              "      <td>103</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.21</td>\n",
              "      <td>0</td>\n",
              "      <td>0.65</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7de4c4dd-907f-4446-80a8-8193dd2e2891')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7de4c4dd-907f-4446-80a8-8193dd2e2891 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7de4c4dd-907f-4446-80a8-8193dd2e2891');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYd1heEfjr1x",
        "outputId": "7f9eae35-e47c-474d-c63f-cd9991de2280"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 400 entries, 0 to 399\n",
            "Data columns (total 8 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   GRE Score          400 non-null    int64  \n",
            " 1   TOEFL Score        400 non-null    int64  \n",
            " 2   University Rating  400 non-null    int64  \n",
            " 3   SOP                400 non-null    float64\n",
            " 4   LOR                400 non-null    float64\n",
            " 5   CGPA               400 non-null    float64\n",
            " 6   Research           400 non-null    int64  \n",
            " 7   Chance of Admit    400 non-null    float64\n",
            "dtypes: float64(4), int64(4)\n",
            "memory usage: 25.1 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXt6ovtWjuar",
        "outputId": "7dfaa38c-3912-4e77-e61e-2b201f7a7794"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[:,0:-1]\n",
        "y = df.iloc[:,-1]"
      ],
      "metadata": {
        "id": "ap0zGZYVjxbI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0)"
      ],
      "metadata": {
        "id": "RZYt3yOpjzzy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "BwEPPRd3j11T",
        "outputId": "2f07628f-e2f4-4d94-e6e0-4783dc3b57d1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
              "336        319          110                  3  3.0   2.5  8.79         0\n",
              "64         325          111                  3  3.0   3.5  8.70         0\n",
              "55         320          103                  3  3.0   3.0  7.70         0\n",
              "106        329          111                  4  4.5   4.5  9.18         1\n",
              "300        309          106                  2  2.5   2.5  8.00         0\n",
              "..         ...          ...                ...  ...   ...   ...       ...\n",
              "323        305          102                  2  2.0   2.5  8.18         0\n",
              "192        322          114                  5  4.5   4.0  8.94         1\n",
              "117        290          104                  4  2.0   2.5  7.46         0\n",
              "47         339          119                  5  4.5   4.0  9.70         0\n",
              "172        322          110                  4  4.0   5.0  9.13         1\n",
              "\n",
              "[320 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2956e80c-18ed-4eea-9d77-b7abb01bf5b9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GRE Score</th>\n",
              "      <th>TOEFL Score</th>\n",
              "      <th>University Rating</th>\n",
              "      <th>SOP</th>\n",
              "      <th>LOR</th>\n",
              "      <th>CGPA</th>\n",
              "      <th>Research</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>336</th>\n",
              "      <td>319</td>\n",
              "      <td>110</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>8.79</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>325</td>\n",
              "      <td>111</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>8.70</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>320</td>\n",
              "      <td>103</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7.70</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>329</td>\n",
              "      <td>111</td>\n",
              "      <td>4</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>9.18</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>309</td>\n",
              "      <td>106</td>\n",
              "      <td>2</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>8.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323</th>\n",
              "      <td>305</td>\n",
              "      <td>102</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>8.18</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>322</td>\n",
              "      <td>114</td>\n",
              "      <td>5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.94</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>290</td>\n",
              "      <td>104</td>\n",
              "      <td>4</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>7.46</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>339</td>\n",
              "      <td>119</td>\n",
              "      <td>5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>9.70</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>322</td>\n",
              "      <td>110</td>\n",
              "      <td>4</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>9.13</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>320 rows Ã— 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2956e80c-18ed-4eea-9d77-b7abb01bf5b9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2956e80c-18ed-4eea-9d77-b7abb01bf5b9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2956e80c-18ed-4eea-9d77-b7abb01bf5b9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKnhXoNbj4RO",
        "outputId": "239a9190-b709-48b8-a01d-35b5560f5982"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "336    0.72\n",
              "64     0.52\n",
              "55     0.64\n",
              "106    0.87\n",
              "300    0.62\n",
              "       ... \n",
              "323    0.62\n",
              "192    0.86\n",
              "117    0.45\n",
              "47     0.89\n",
              "172    0.86\n",
              "Name: Chance of Admit , Length: 320, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "X_train_trf = scaler.fit_transform(X_train)\n",
        "X_test_trf = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "AeSPkxK0j6xC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_trf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80KCBHenj9Ti",
        "outputId": "ebe00444-5cb3-483c-8a30-4ff241160dfb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.58      , 0.64285714, 0.5       , ..., 0.375     , 0.63782051,\n",
              "        0.        ],\n",
              "       [0.7       , 0.67857143, 0.5       , ..., 0.625     , 0.60897436,\n",
              "        0.        ],\n",
              "       [0.6       , 0.39285714, 0.5       , ..., 0.5       , 0.28846154,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [0.        , 0.42857143, 0.75      , ..., 0.375     , 0.21153846,\n",
              "        0.        ],\n",
              "       [0.98      , 0.96428571, 1.        , ..., 0.75      , 0.92948718,\n",
              "        0.        ],\n",
              "       [0.64      , 0.64285714, 0.75      , ..., 1.        , 0.74679487,\n",
              "        1.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential \n",
        "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout"
      ],
      "metadata": {
        "id": "AL6xeaTcj_k0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(28,activation='relu',input_dim=7))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(14,activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(7,activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(1,activation='linear'))"
      ],
      "metadata": {
        "id": "zu9rO5lRkMIK"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctcz-UeXk0eh",
        "outputId": "d75d9f9b-959f-40c1-8925-8693d91cbb5d"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_41 (Dense)            (None, 28)                224       \n",
            "                                                                 \n",
            " dropout_32 (Dropout)        (None, 28)                0         \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 14)                406       \n",
            "                                                                 \n",
            " dropout_33 (Dropout)        (None, 14)                0         \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 7)                 105       \n",
            "                                                                 \n",
            " dropout_34 (Dropout)        (None, 7)                 0         \n",
            "                                                                 \n",
            " dense_44 (Dense)            (None, 1)                 8         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 743\n",
            "Trainable params: 743\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='mean_squared_error',optimizer='rmsprop',metrics=['accuracy'])\n",
        "history = model.fit(X_train_trf,y_train, epochs=100,validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5Msjio1k3ds",
        "outputId": "e5eaca66-d296-4ace-fb40-166e0f45852d"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 35ms/step - loss: 0.2536 - accuracy: 0.0000e+00 - val_loss: 0.1048 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1136 - accuracy: 0.0000e+00 - val_loss: 0.0344 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0787 - accuracy: 0.0000e+00 - val_loss: 0.0182 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0812 - accuracy: 0.0000e+00 - val_loss: 0.0154 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0702 - accuracy: 0.0000e+00 - val_loss: 0.0149 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0624 - accuracy: 0.0000e+00 - val_loss: 0.0100 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0583 - accuracy: 0.0000e+00 - val_loss: 0.0111 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0588 - accuracy: 0.0000e+00 - val_loss: 0.0109 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0409 - accuracy: 0.0000e+00 - val_loss: 0.0102 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0431 - accuracy: 0.0000e+00 - val_loss: 0.0093 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0357 - accuracy: 0.0000e+00 - val_loss: 0.0121 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0405 - accuracy: 0.0000e+00 - val_loss: 0.0131 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0408 - accuracy: 0.0000e+00 - val_loss: 0.0097 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0342 - accuracy: 0.0000e+00 - val_loss: 0.0111 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0367 - accuracy: 0.0000e+00 - val_loss: 0.0098 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0290 - accuracy: 0.0000e+00 - val_loss: 0.0146 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0387 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0326 - accuracy: 0.0000e+00 - val_loss: 0.0087 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0224 - accuracy: 0.0000e+00 - val_loss: 0.0099 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0265 - accuracy: 0.0000e+00 - val_loss: 0.0107 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0239 - accuracy: 0.0000e+00 - val_loss: 0.0088 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0270 - accuracy: 0.0000e+00 - val_loss: 0.0094 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0252 - accuracy: 0.0000e+00 - val_loss: 0.0053 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0177 - accuracy: 0.0000e+00 - val_loss: 0.0068 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0226 - accuracy: 0.0000e+00 - val_loss: 0.0060 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0206 - accuracy: 0.0000e+00 - val_loss: 0.0083 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0179 - accuracy: 0.0000e+00 - val_loss: 0.0119 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0210 - accuracy: 0.0000e+00 - val_loss: 0.0104 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0190 - accuracy: 0.0000e+00 - val_loss: 0.0064 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0187 - accuracy: 0.0000e+00 - val_loss: 0.0066 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0202 - accuracy: 0.0000e+00 - val_loss: 0.0065 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0172 - accuracy: 0.0000e+00 - val_loss: 0.0072 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0156 - accuracy: 0.0000e+00 - val_loss: 0.0076 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0154 - accuracy: 0.0000e+00 - val_loss: 0.0071 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0161 - accuracy: 0.0000e+00 - val_loss: 0.0077 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0178 - accuracy: 0.0000e+00 - val_loss: 0.0079 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0195 - accuracy: 0.0000e+00 - val_loss: 0.0094 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0123 - accuracy: 0.0000e+00 - val_loss: 0.0101 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0181 - accuracy: 0.0000e+00 - val_loss: 0.0077 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0218 - accuracy: 0.0000e+00 - val_loss: 0.0069 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0177 - accuracy: 0.0000e+00 - val_loss: 0.0081 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0145 - accuracy: 0.0000e+00 - val_loss: 0.0096 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0146 - accuracy: 0.0000e+00 - val_loss: 0.0089 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0137 - accuracy: 0.0000e+00 - val_loss: 0.0063 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0162 - accuracy: 0.0000e+00 - val_loss: 0.0080 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0141 - accuracy: 0.0000e+00 - val_loss: 0.0087 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0142 - accuracy: 0.0000e+00 - val_loss: 0.0106 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0134 - accuracy: 0.0000e+00 - val_loss: 0.0077 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0160 - accuracy: 0.0000e+00 - val_loss: 0.0079 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0123 - accuracy: 0.0000e+00 - val_loss: 0.0092 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0139 - accuracy: 0.0000e+00 - val_loss: 0.0095 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0132 - accuracy: 0.0000e+00 - val_loss: 0.0077 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0165 - accuracy: 0.0000e+00 - val_loss: 0.0078 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0124 - accuracy: 0.0000e+00 - val_loss: 0.0076 - val_accuracy: 0.0000e+00\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0125 - accuracy: 0.0000e+00 - val_loss: 0.0056 - val_accuracy: 0.0000e+00\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0119 - accuracy: 0.0000e+00 - val_loss: 0.0062 - val_accuracy: 0.0000e+00\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0123 - accuracy: 0.0000e+00 - val_loss: 0.0068 - val_accuracy: 0.0000e+00\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0127 - accuracy: 0.0000e+00 - val_loss: 0.0064 - val_accuracy: 0.0000e+00\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0115 - accuracy: 0.0000e+00 - val_loss: 0.0069 - val_accuracy: 0.0000e+00\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0108 - accuracy: 0.0000e+00 - val_loss: 0.0078 - val_accuracy: 0.0000e+00\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0112 - accuracy: 0.0000e+00 - val_loss: 0.0066 - val_accuracy: 0.0000e+00\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0105 - accuracy: 0.0000e+00 - val_loss: 0.0073 - val_accuracy: 0.0000e+00\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0122 - accuracy: 0.0000e+00 - val_loss: 0.0052 - val_accuracy: 0.0000e+00\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0132 - accuracy: 0.0000e+00 - val_loss: 0.0057 - val_accuracy: 0.0000e+00\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0118 - accuracy: 0.0000e+00 - val_loss: 0.0054 - val_accuracy: 0.0000e+00\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0108 - accuracy: 0.0000e+00 - val_loss: 0.0100 - val_accuracy: 0.0000e+00\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0130 - accuracy: 0.0000e+00 - val_loss: 0.0068 - val_accuracy: 0.0000e+00\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0111 - accuracy: 0.0000e+00 - val_loss: 0.0056 - val_accuracy: 0.0000e+00\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0104 - accuracy: 0.0000e+00 - val_loss: 0.0080 - val_accuracy: 0.0000e+00\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0113 - accuracy: 0.0000e+00 - val_loss: 0.0071 - val_accuracy: 0.0000e+00\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0123 - accuracy: 0.0000e+00 - val_loss: 0.0063 - val_accuracy: 0.0000e+00\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0120 - accuracy: 0.0000e+00 - val_loss: 0.0067 - val_accuracy: 0.0000e+00\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0120 - accuracy: 0.0000e+00 - val_loss: 0.0071 - val_accuracy: 0.0000e+00\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0138 - accuracy: 0.0000e+00 - val_loss: 0.0064 - val_accuracy: 0.0000e+00\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0108 - accuracy: 0.0000e+00 - val_loss: 0.0072 - val_accuracy: 0.0000e+00\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0112 - accuracy: 0.0000e+00 - val_loss: 0.0064 - val_accuracy: 0.0000e+00\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0135 - accuracy: 0.0000e+00 - val_loss: 0.0068 - val_accuracy: 0.0000e+00\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0127 - accuracy: 0.0000e+00 - val_loss: 0.0056 - val_accuracy: 0.0000e+00\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0118 - accuracy: 0.0000e+00 - val_loss: 0.0074 - val_accuracy: 0.0000e+00\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0113 - accuracy: 0.0000e+00 - val_loss: 0.0065 - val_accuracy: 0.0000e+00\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0091 - accuracy: 0.0000e+00 - val_loss: 0.0070 - val_accuracy: 0.0000e+00\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0070 - val_accuracy: 0.0000e+00\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0072 - val_accuracy: 0.0000e+00\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0093 - accuracy: 0.0000e+00 - val_loss: 0.0091 - val_accuracy: 0.0000e+00\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0128 - accuracy: 0.0000e+00 - val_loss: 0.0068 - val_accuracy: 0.0000e+00\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0094 - accuracy: 0.0000e+00 - val_loss: 0.0070 - val_accuracy: 0.0000e+00\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0100 - accuracy: 0.0000e+00 - val_loss: 0.0061 - val_accuracy: 0.0000e+00\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0091 - accuracy: 0.0000e+00 - val_loss: 0.0064 - val_accuracy: 0.0000e+00\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0101 - accuracy: 0.0000e+00 - val_loss: 0.0076 - val_accuracy: 0.0000e+00\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0099 - accuracy: 0.0000e+00 - val_loss: 0.0059 - val_accuracy: 0.0000e+00\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0104 - accuracy: 0.0000e+00 - val_loss: 0.0070 - val_accuracy: 0.0000e+00\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0094 - accuracy: 0.0000e+00 - val_loss: 0.0057 - val_accuracy: 0.0000e+00\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0103 - accuracy: 0.0000e+00 - val_loss: 0.0059 - val_accuracy: 0.0000e+00\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0089 - accuracy: 0.0000e+00 - val_loss: 0.0074 - val_accuracy: 0.0000e+00\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0095 - accuracy: 0.0000e+00 - val_loss: 0.0069 - val_accuracy: 0.0000e+00\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0103 - accuracy: 0.0000e+00 - val_loss: 0.0063 - val_accuracy: 0.0000e+00\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0100 - accuracy: 0.0000e+00 - val_loss: 0.0068 - val_accuracy: 0.0000e+00\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0087 - accuracy: 0.0000e+00 - val_loss: 0.0080 - val_accuracy: 0.0000e+00\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0073 - val_accuracy: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test_trf)\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vr-4UlCflC9P",
        "outputId": "41ff023f-0e09-476f-be40-8ffbab577346"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9da2dbf8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.65472233],\n",
              "       [0.6612031 ],\n",
              "       [0.73612463],\n",
              "       [0.5999075 ],\n",
              "       [0.6601817 ],\n",
              "       [0.5948285 ],\n",
              "       [0.6655637 ],\n",
              "       [0.6343075 ],\n",
              "       [0.77351975],\n",
              "       [0.83694005],\n",
              "       [0.5545733 ],\n",
              "       [0.8161018 ],\n",
              "       [0.66837484],\n",
              "       [0.5189327 ],\n",
              "       [0.7928434 ],\n",
              "       [0.59581596],\n",
              "       [0.6068651 ],\n",
              "       [0.7308748 ],\n",
              "       [0.60446703],\n",
              "       [0.6655387 ],\n",
              "       [0.83246386],\n",
              "       [0.7485879 ],\n",
              "       [0.6325327 ],\n",
              "       [0.5275548 ],\n",
              "       [0.7495488 ],\n",
              "       [0.581178  ],\n",
              "       [0.5692607 ],\n",
              "       [0.62894845],\n",
              "       [0.8488798 ],\n",
              "       [0.6256274 ],\n",
              "       [0.6248325 ],\n",
              "       [0.70914567],\n",
              "       [0.7133926 ],\n",
              "       [0.56422395],\n",
              "       [0.71204066],\n",
              "       [0.72499436],\n",
              "       [0.6737771 ],\n",
              "       [0.7892957 ],\n",
              "       [0.6125531 ],\n",
              "       [0.8619133 ],\n",
              "       [0.7020347 ],\n",
              "       [0.6446202 ],\n",
              "       [0.688361  ],\n",
              "       [0.7549309 ],\n",
              "       [0.7532308 ],\n",
              "       [0.6497054 ],\n",
              "       [0.58580995],\n",
              "       [0.6762663 ],\n",
              "       [0.6035095 ],\n",
              "       [0.5908666 ],\n",
              "       [0.6335418 ],\n",
              "       [0.7164067 ],\n",
              "       [0.61095834],\n",
              "       [0.82430756],\n",
              "       [0.69134724],\n",
              "       [0.6979101 ],\n",
              "       [0.77433944],\n",
              "       [0.7101142 ],\n",
              "       [0.7038416 ],\n",
              "       [0.7845056 ],\n",
              "       [0.682184  ],\n",
              "       [0.5236254 ],\n",
              "       [0.6094054 ],\n",
              "       [0.55981123],\n",
              "       [0.7760862 ],\n",
              "       [0.738722  ],\n",
              "       [0.6705172 ],\n",
              "       [0.8198223 ],\n",
              "       [0.68910277],\n",
              "       [0.69545823],\n",
              "       [0.60462606],\n",
              "       [0.7976577 ],\n",
              "       [0.7286173 ],\n",
              "       [0.6442617 ],\n",
              "       [0.8314282 ],\n",
              "       [0.6401181 ],\n",
              "       [0.61086774],\n",
              "       [0.6138653 ],\n",
              "       [0.83196414],\n",
              "       [0.5168206 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "r2_score(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RrfaeaRl5Z5",
        "outputId": "27a47f5c-eebc-46f1-be3f-6b6ee949a675"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6208147606653627"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "4yttZEKVl_LS",
        "outputId": "953fe1d2-c3ba-4982-d22f-7504c11aa203"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f9da2e1c910>]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "NOrfdlMVm7X2",
        "outputId": "65e1749b-290b-47c9-cecd-e64178b30d86"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f9da292af10>]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kquOYpTRnDDk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}